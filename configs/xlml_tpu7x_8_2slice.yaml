benchmarks:
- benchmark_name: ppermute
  benchmark_sweep_params:
  - {matrix_dim_range: {start: 1024, end: 20000, increase_by: 1024}, dtype: "bfloat16", dcn_size_range: 2, ici_size_range: 4}
  xlml_metrics_dir: "/tmp/microbenchmarks/outputs"
- benchmark_name: all_gather
  benchmark_sweep_params:
  - {matrix_dim_range: {start: 1024, end: 20000, increase_by: 1024}, dtype: "bfloat16", dcn_size_range: 2, ici_size_range: 4}
  xlml_metrics_dir: "/tmp/microbenchmarks/outputs"
- benchmark_name: psum
  benchmark_sweep_params:
  - {matrix_dim_range: {start: 1024, end: 20000, increase_by: 1024}, dtype: "bfloat16", dcn_size_range: 2, ici_size_range: 4}
  xlml_metrics_dir: "/tmp/microbenchmarks/outputs"
- benchmark_name: psum_scatter
  benchmark_sweep_params:
  - {matrix_dim_range: {start: 1024, end: 20000, increase_by: 1024}, dtype: "bfloat16", dcn_size_range: 2, ici_size_range: 4}
  xlml_metrics_dir: "/tmp/microbenchmarks/outputs"
- benchmark_name: all_to_all
  benchmark_sweep_params:
  - {matrix_dim_range: {start: 1024, end: 20000, increase_by: 1024}, dtype: "bfloat16", dcn_size_range: 2, ici_size_range: 4}
  xlml_metrics_dir: "/tmp/microbenchmarks/outputs"
- benchmark_name: "naive_matmul"
  benchmark_sweep_params:
  - {m_range: {start: 1024, end: 32768, increase_by: 1024}, k: "SAME_AS_m", n: "SAME_AS_m"}
  xlml_metrics_dir: "/tmp/microbenchmarks/outputs"
- benchmark_name: "single_host_naive_matmul"
  benchmark_sweep_params:
  - {m_range: {start: 1024, end: 32768, increase_by: 1024}, k: "SAME_AS_m", n: "SAME_AS_m"}
  xlml_metrics_dir: "/tmp/microbenchmarks/outputs"
- benchmark_name: "multilayer_collective_matmul"
  benchmark_sweep_params:
  - {m_range: {start: 1024, end: 32768, increase_by: 1024}, k: "SAME_AS_m", n: "SAME_AS_m"}
  xlml_metrics_dir: "/tmp/microbenchmarks/outputs"
- benchmark_name: "collective_matmul_one_direction"
  benchmark_sweep_params:
  - {m_range: {start: 1024, end: 32768, increase_by: 1024}, k: "SAME_AS_m", n: "SAME_AS_m"}
  xlml_metrics_dir: "/tmp/microbenchmarks/outputs"
- benchmark_name: "collective_matmul_two_directions"
  benchmark_sweep_params:
  - {m_range: {start: 1024, end: 32768, increase_by: 1024}, k: "SAME_AS_m", n: "SAME_AS_m"}
  xlml_metrics_dir: "/tmp/microbenchmarks/outputs"
- benchmark_name: "naive_attention"
  benchmark_sweep_params:
  - {batch_range: {start: 1, end: 32, multiplier: 2}, seq_len: 512, d_model: 1024, num_heads: 1, causal: true, scale: false}
  - {batch: 2, seq_len_range: {start: 128, end: 2048, multiplier: 2}, d_model: 1024, num_heads: 1, causal: true, scale: false}
  - {batch: 2, seq_len: 512, d_model_range: {start: 128, end: 4096, multiplier: 2}, num_heads: 1, causal: true, scale: false}
  - {batch: 2, seq_len: 512, d_model: 2048, num_heads_range: {start: 1, end: 16, multiplier: 2}, causal: true, scale: false}
  - {batch: 2, seq_len: 512, d_model: 1024, num_heads: 1, causal: false, scale: false}
  - {batch: 2, seq_len: 512, d_model: 1024, num_heads: 1, causal: true, scale: true}
  xlml_metrics_dir: "/tmp/microbenchmarks/outputs"
- benchmark_name: "pallas_flash_attention"
  benchmark_sweep_params:
  - {batch_range: {start: 1, end: 32, multiplier: 2}, seq_len: 512, d_model: 1024, num_heads: 1, causal: true}
  - {batch: 2, seq_len_range: {start: 128, end: 2048, multiplier: 2}, d_model: 1024, num_heads: 1, causal: true}
  - {batch: 2, seq_len: 512, d_model_range: {start: 128, end: 4096, multiplier: 2}, num_heads: 1, causal: true}
  - {batch: 2, seq_len: 512, d_model: 2048, num_heads_range: {start: 1, end: 16, multiplier: 2}, causal: true}
  - {batch: 2, seq_len: 512, d_model: 1024, num_heads: 1, causal: false}
  xlml_metrics_dir: "/tmp/microbenchmarks/outputs"
- benchmark_name: "splash_attention"
  benchmark_sweep_params:
  - {batch_range: {start: 1, end: 32, multiplier: 2}, seq_len: 512, d_model: 1024, num_heads: 1, causal: true}
  - {batch: 2, seq_len_range: {start: 128, end: 2048, multiplier: 2}, d_model: 1024, num_heads: 1, causal: true}
  - {batch: 2, seq_len: 512, d_model_range: {start: 128, end: 4096, multiplier: 2}, num_heads: 1, causal: true}
  - {batch: 2, seq_len: 512, d_model: 2048, num_heads_range: {start: 1, end: 16, multiplier: 2}, causal: true}
  - {batch: 2, seq_len: 512, d_model: 1024, num_heads: 1, causal: false}
  xlml_metrics_dir: "/tmp/microbenchmarks/outputs"
- benchmark_name: "flax_nnx_attention"
  benchmark_sweep_params:
  - {batch_range: {start: 1, end: 32, multiplier: 2}, seq_len: 512, d_model: 1024, num_heads: 1}
  - {batch: 2, seq_len_range: {start: 128, end: 2048, multiplier: 2}, d_model: 1024, num_heads: 1}
  - {batch: 2, seq_len: 512, d_model_range: {start: 128, end: 4096, multiplier: 2}, num_heads: 1}
  - {batch: 2, seq_len: 512, d_model: 2048, num_heads_range: {start: 1, end: 16, multiplier: 2}}
  xlml_metrics_dir: "/tmp/microbenchmarks/outputs"
- benchmark_name: "flax_linen_attention"
  benchmark_sweep_params:
  - {batch_range: {start: 1, end: 32, multiplier: 2}, seq_len: 512, d_model: 1024, num_heads: 1}
  - {batch: 2, seq_len_range: {start: 128, end: 2048, multiplier: 2}, d_model: 1024, num_heads: 1}
  - {batch: 2, seq_len: 512, d_model_range: {start: 128, end: 4096, multiplier: 2}, num_heads: 1}
  - {batch: 2, seq_len: 512, d_model: 2048, num_heads_range: {start: 1, end: 16, multiplier: 2}}
  xlml_metrics_dir: "/tmp/microbenchmarks/outputs"
- benchmark_name: "keras_attention"
  benchmark_sweep_params:
  - {batch_range: {start: 1, end: 32, multiplier: 2}, seq_len: 512, d_model: 1024, num_heads: 1}
  - {batch: 2, seq_len_range: {start: 128, end: 2048, multiplier: 2}, d_model: 1024, num_heads: 1}
  - {batch: 2, seq_len: 512, d_model_range: {start: 128, end: 4096, multiplier: 2}, num_heads: 1}
  - {batch: 2, seq_len: 512, d_model: 2048, num_heads_range: {start: 1, end: 16, multiplier: 2}}
  xlml_metrics_dir: "/tmp/microbenchmarks/outputs"
- benchmark_name: "numpy_convolve"
  benchmark_sweep_params:
  - {input_size_range: {start: 256, end: 512, multiplier: 2}, kernel_size: 3, padding_mode: "same"}
  - {input_size: 2048, kernel_size_range: {start: 3, end: 128, multiplier: 2}, padding_mode: "valid"}
  - {input_size: 2048, kernel_size: 127, padding_mode: "full"}
  xlml_metrics_dir: "/tmp/microbenchmarks/outputs"
- benchmark_name: "scipy_signal_convolve"
  benchmark_sweep_params:
  - {input_size_range: {start: 256, end: 1024, multiplier: 2}, kernel_size: 3, dimension: 2, padding_mode: "same"}
  - {input_size: 128, kernel_size: 3, dimension: 3, padding_mode: "valid"}
  xlml_metrics_dir: "/tmp/microbenchmarks/outputs"
- benchmark_name: "scipy_signal_convolve2d"
  benchmark_sweep_params:
  - {input_size_range: {start: 256, end: 512, multiplier: 2}, kernel_size: 3, padding_mode: "valid"}
  - {input_size: 1024, kernel_size: 63, padding_mode: "valid"}
  - {input_size: 1024, kernel_size: 127, padding_mode: "valid"}
  xlml_metrics_dir: "/tmp/microbenchmarks/outputs"
- benchmark_name: "lax_conv_general_dilated"
  benchmark_sweep_params:
  - {batch_size_range: {start: 16, end: 32, multiplier: 2}, input_h: 1024, input_w: 1024, kernel_h: 255, kernel_w: 255, in_channel: 16, out_channel: 16, padding_mode: "valid", stride: 1, dilation: 1, dtype: "bfloat16"}
  - {batch_size_range: 16, input_h: 128, input_w: 128, kernel_h: 63, kernel_w: 63, in_channel: 16, out_channel: 16, padding_mode: "valid", stride: 1, dilation: 1, dtype: "bfloat16"}
  xlml_metrics_dir: "/tmp/microbenchmarks/outputs"
